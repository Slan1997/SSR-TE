## This file is used to combine individual result files into a full dataset 
# for each of the R simulation files, i.e., alpha_OLStest.R, alpha_permutation.R, power_OLStest.R, power_permutation.R

## there are 4 output files generated by this code:
# 1. alpha_newdf729.csv (Type I error (alpha) exact small sample OLS test)
# 2. 1e4debug_perm2e3_729.csv (Type I error (alpha) Permutation test)
# 3. power_newdf_729.csv (Power exact small sample OLS test)
# 4. power1e4_perm2e3_729.csv (Power Permutation test)

library(pacman)
pacman::p_load(tidyr, dplyr,readr,stringr)

############################################## Type I error (alpha)
#################### Type I error (alpha) exact small sample OLS test
result_path = paste0(getwd(),'/result_alpha729/')
list.files <- list.files(path = result_path, "^debug715_1e6newdf.*")
idx = as.numeric(gsub('debug715_1e6newdf([0-9]+).csv','\\1',list.files))
idx
num_scena = 72

list.files=list.files[order(idx)]
list.files
# Initiate a blank data frame 
alpha <- rep(NA,num_scena )
# combine datasets
for (i in (1:num_scena )){
  if (! i %in% (1:num_scena )[ !(1:num_scena ) %in% idx ]){
    temp_data <- read_csv(paste0(result_path,
                                 list.files[grepl(paste0('debug715_1e6newdf',i,'.csv'),list.files)]))
    alpha[i] <- pull(temp_data)
  }
}
alpha

scenarios = expand.grid(n_control = c(16,30,60,120,1000,2000),
                        alloc_ratio = c(1,2),
                        SSR = c('no', 'yes'),
                        beta = c(.1,.2)
)  %>%
  as.data.frame

scenarios1 = expand.grid(n_control = c(1500,2500,3000),
                         alloc_ratio = c(1,2),
                         SSR = c('no', 'yes'),
                         beta = c(.1,.2)
)  %>%
  as.data.frame

scenarios = bind_rows(scenarios,scenarios1) 
scenarios

scenarios$alpha = alpha

write_csv(scenarios,paste0(getwd(),"/alpha_newdf729.csv"))

#################### Type I error (alpha) Permutation test
result_path = '~/adaptive_design/alpha_scena/result_alpha_perm729/'

run = cbind(run_idx = 1:2400,
            data.frame(expand.grid(scena = 1:48,sub_sim=1:50)) )

head(run)

scenarios = expand.grid(n_control = c(16,30,60,120,1000,2000),
                        alloc_ratio = c(1,2),
                        SSR = c('no', 'yes'),
                        beta = c(.1,.2)
) %>% #filter(!(endpoint_selection=='yes' & SSR=='no')) %>%
  as.data.frame
scenarios 

list.files <- list.files(path = result_path, "debug_perm([0-9]+).csv")
idx = as.numeric(gsub('debug_perm([0-9]+).csv','\\1',list.files))
idx
length(idx)

list.files=list.files[order(idx)]
list.files

# Initiate a blank data frame 
combined_dt <- tibble()
# combine datasets
for (i in 1:length(list.files)){
  temp_data <- read_csv(paste0(result_path,list.files[i]))
  combined_dt <- bind_rows(combined_dt, temp_data)
}
dim(combined_dt)
dim(temp_data)

combined_dt1 = left_join(combined_dt,run,by="run_idx")
final_alpha=combined_dt %>% group_by(scena) %>% 
  summarise(alpha = mean(rej_final_ind)) %>% as.data.frame

left_join(scenarios%>% mutate(scena=1:nrow(scenarios)) ,
          final_alpha ,by ="scena") %>% 
  write_csv("1e4debug_perm2e3_729.csv")

############################################################################################

############################################## Power
scenarios = expand.grid(
  alloc_ratio = c(1,2),
  #endpoint_selection = c('no','yes'),
  SSR = c('no', 'yes'),
  theta_k = c(.2,.5,.8),
  beta=c(.1,.2)) 

### formula to get initial planned sample size N_total
get_initial_tot_ss = function(beta0,r,theta_k,n_endpts=6,alpha0=.025,rho=.3){
  (n_endpts + n_endpts*(n_endpts-1)*rho)/n_endpts^2 *(1/r+1)*(1+r)*
    ( (qnorm(1-alpha0)+qnorm(1-beta0)) / theta_k   )^2   
}

N_tot = get_initial_tot_ss(beta0=scenarios$beta,r=scenarios$alloc_ratio,theta_k=scenarios$theta_k)
## get the total control and treatment sample sizes
n_control = 2*ceiling(N_tot/(1+scenarios$alloc_ratio)/2)
n_treatment = scenarios$alloc_ratio * n_control
n_control
n_treatment
scenarios0 = scenarios %>% mutate(n_control)

### add the scenarios for underestimated initially planned sample sizes
scenarios1 = scenarios
scenarios1$n_control = ceiling(scenarios0$n_control *.6)
n_control_shrink = scenarios1$n_control
# force the odd total sample sizes to be even.
n_control_shrink[scenarios1$n_control%%2!=0]= scenarios1$n_control[scenarios1$n_control%%2!=0] + 1
n_control_shrink 
scenarios1$n_control = n_control_shrink 

## combine both IPSS types to be the full scenarios
scenarios = bind_rows(scenarios0,scenarios1) %>% mutate(shrink_factor=rep(c(1,.6),each=24))
scenarios # nrow = 48

#################### Power exact small sample OLS test
result_path = paste0('~/adaptive_design/721scenaplan/result_power729/')
list.files <- list.files(path = result_path, "^721_newdf([0-9]+).csv")
idx = as.numeric(gsub('721_newdf([0-9]+).csv','\\1',list.files))
idx
num_scena = 48
(1:num_scena )[ !(1:num_scena ) %in% idx ]
list.files=list.files[order(idx)]
list.files

# Initiate a blank data frame 
power <- rep(NA,num_scena )
# combine datasets
for (i in (1:num_scena )){
  if (! i %in% (1:num_scena )[ !(1:num_scena ) %in% idx ]){
    temp_data <- read_csv(paste0(result_path,
                                 list.files[grepl(paste0('721_newdf',i,'.csv'),list.files)]))
    power[i] <- pull(temp_data)
  }
}
power 

new_N_ct <- rep(NA,num_scena) # mean of actual sample size used in the trial
max_N_ct = rep(NA,num_scena ) # maximum sample sizes
# combine datasets
for (i in (1:num_scena )){
  if (! i %in% (1:num_scena )[ !(1:num_scena ) %in% idx ]){
    temp_data <- read_csv(paste0(result_path,
                                 paste0('table721_newdf',i,'.csv'))) 
    # Total sample size of control group
    N_ct = scenarios$n_control[unique(temp_data$scena)] # one temp_data only contains 1 scenario

    M_ct = temp_data$new_sample_size_ct 
    M_ct[temp_data$stop_at_interim_ind==2] = N_ct/2 # if stop early, then the actual sample size is actually half of the original total sample size
    
    new_N_ct[i] <- mean(M_ct)
    max_N_ct[i] = max(M_ct)
  }
}

bind_cols(scenarios, power=power,mean_new_N_ct=new_N_ct,
          max_N_ct =max_N_ct ) %>% 
  write_csv("~/adaptive_design/721scenaplan/power_newdf_729.csv")


#################### Power Permutation test
result_path = paste0('~/adaptive_design/721scenaplan/result_power_perm729/')

run = cbind(run_idx = 1:2400,
            data.frame(expand.grid(scena = 1:48,sub_sim=1:50)) )

head(run)

list.files <- list.files(path = result_path, "perm([0-9]+).csv")
idx = as.numeric(gsub('perm([0-9]+).csv','\\1',list.files))
idx

num_scena = 2400
# check if any file is missing
(1:num_scena )[ !(1:num_scena ) %in% idx ]

list.files=list.files[order(idx)]
list.files

# Initiate a blank data frame 
combined_dt <- tibble()
# combine datasets
for (i in 1:length(list.files)){
  if (! i %in% (1:num_scena )[ !(1:num_scena ) %in% idx ]){ # in case some files are missing, if so, skip those file index
    temp_data <- read_csv(paste0(result_path,
                                 list.files[grepl(paste0('perm',i,'.csv'),list.files)]))
    combined_dt <- bind_rows(combined_dt, temp_data)
  }
}
dim(combined_dt)

combined_dt2 = full_join(combined_dt,
                         scenarios%>% mutate(scena=1:nrow(scenarios)), 
                         by="scena")

new_N_ct0= combined_dt2$new_sample_size_ct
# if stop early (new_sample_size_ct will be missing), then assign half of the N_ct as the actual control group sample size
new_N_ct0[is.na(combined_dt2$new_sample_size_ct)] = 1/2 * combined_dt2$n_control[is.na(combined_dt2$new_sample_size_ct)]

all( (combined_dt2$stop_at_interim_ind==2) == (is.na(combined_dt2$new_sample_size_ct)) )

final_power=combined_dt2 %>% group_by(scena) %>% 
  summarise(power = mean(rej_final_ind)) %>% as.data.frame

new_N_ct = combined_dt2 %>% mutate(new_N_ct0)%>% 
  group_by(scena) %>% 
  summarise(new_N_ct= mean(new_N_ct0),
            max_N_ct = max(new_N_ct0)) 

full_join(scenarios%>% mutate(scena=1:nrow(scenarios)) ,
          full_join(final_power,new_N_ct,by='scena') ,by ="scena") %>% 
  rename(mean_new_N_ct= new_N_ct) %>% write_csv("power1e4_perm2e3_729.csv")


